{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Text Classification",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPd9nMxC+RBun4l5USOiYau",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdulmoiz99/Keras-Text-Classification/blob/main/Keras_Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xWpbumuBj0O",
        "outputId": "17411f32-df60-470e-deea-5d8e9a4a087c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence    Wow... Loved this place.\n",
            "label                              1\n",
            "source                          yelp\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "filepath_dict = { 'yelp': '/content/sample_data/data/yelp_labelled.txt',\n",
        "                  'amazon': '/content/sample_data/data/amazon_cells_labelled.txt',\n",
        "                  'imdb': '/content/sample_data/data/imdb_labelled.txt'}\n",
        "\n",
        "df_list = []\n",
        "\n",
        "for source, filepath in filepath_dict.items():\n",
        "  df = pd.read_csv(filepath, names = ['sentence', 'label'], sep ='\\t')\n",
        "  df['source'] = source\n",
        "  df_list.append(df)\n",
        "\n",
        "df = pd.concat(df_list)\n",
        "print(df.iloc[0])  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_yelp = df[df['source'] == 'yelp']\n",
        "\n",
        "sentences = df_yelp['sentence'].values\n",
        "y = df_yelp['label'].values\n",
        "\n",
        "sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
        "    sentences,y,test_size = 0.25, random_state = 1000\n",
        ")"
      ],
      "metadata": {
        "id": "LyZtvddsFQeE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(sentences_train)\n",
        "\n",
        "X_train = vectorizer.transform(sentences_train)\n",
        "X_test = vectorizer.transform(sentences_test)\n"
      ],
      "metadata": {
        "id": "Xy9TjR5fFQZI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5MWnBODFQWU",
        "outputId": "92ffae6e-891a-41b4-c399-45897dcfd6ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<750x1714 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 7368 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q58D8dDHFQT-",
        "outputId": "d41e5316-e568-45b5-b55e-7f2fb7288606"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<250x1714 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 2069 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "score = classifier.score(X_test,y_test)\n",
        "\n",
        "print(\"Accuracy: \",score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuLM8EELFQRF",
        "outputId": "7909acb4-85a7-480e-bdd7-6a0ee3db90d6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for source in df['source'].unique():\n",
        "  df_source = df[df['source'] == source]\n",
        "  sentences = df_source['sentence'].values\n",
        "  y = df_source['label'].values\n",
        "\n",
        "  sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
        "      sentences, y, test_size = 0.25, random_state = 10000\n",
        "  )\n",
        "\n",
        "  vectorizer = CountVectorizer()\n",
        "  vectorizer.fit(sentences_train)\n",
        "  vectorizer.fit(sentences_test)\n",
        "  X_train = vectorizer.transform(sentences_train)\n",
        "  X_test = vectorizer.transform(sentences_test)\n",
        "\n",
        "\n",
        "  classifier = LogisticRegression()\n",
        "  classifier.fit(X_train, y_train)\n",
        "  score = classifier.score(X_test,y_test)\n",
        "  print('Accuracy for {} data: {:,.4f}'.format(source,score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz8HEngSI-Zq",
        "outputId": "e44d2e28-cb5c-4ac2-a569-160ca16633ce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for yelp data: 0.8000\n",
            "Accuracy for amazon data: 0.8040\n",
            "Accuracy for imdb data: 0.7701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdPOtxjxI-Wl",
        "outputId": "c822db46-aedf-46a5-e1c6-c1d0e218643f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation ='relu'))\n",
        "model.add(layers.Dense(1,activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "uYrzo6yQI-Sy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dm5kd5WI-Pz",
        "outputId": "fdf394df-a067-48f9-95a9-219a4a100515"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                11990     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,001\n",
            "Trainable params: 12,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs = 20,\n",
        "                    verbose = False,\n",
        "                    validation_data=(X_test,y_test),\n",
        "                    batch_size = 10 \n",
        "                    )"
      ],
      "metadata": {
        "id": "9fv3s2A1I-Me"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import clear_session\n",
        "clear_session()"
      ],
      "metadata": {
        "id": "RrlQ1XbPPvG5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_train,y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test,y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjCunPLeP2Uh",
        "outputId": "53023551-ed18-4020-94e4-fd394b888f49"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 1.0000\n",
            "Testing Accuracy: 0.7487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "MDn35gMtRBx5",
        "outputId": "426a189b-eb55-498c-ec08-f57f9253b351"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-91c9fccd45a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()"
      ],
      "metadata": {
        "id": "Th6pXFysP2Rl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What Is a Word Embedding?"
      ],
      "metadata": {
        "id": "OthldLdkWWmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cities = ['London', 'Berlin', 'Berlin', 'New York', 'Canada']\n",
        "\n",
        "cities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6ZCzVfxP2Oj",
        "outputId": "d5a66d1b-9775-4d42-d607-5622fb963063"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['London', 'Berlin', 'Berlin', 'New York', 'Canada']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "city_labels = encoder.fit_transform(cities)\n",
        "\n",
        "city_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9V5Zk28P2Lj",
        "outputId": "492c4657-ac9b-42c2-9e7a-5c33fb4a9ce9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 0, 3, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(sparse = False)\n",
        "city_labels =city_labels.reshape((5,1))\n",
        "\n",
        "encoder.fit_transform(city_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56bMMZarP2IP",
        "outputId": "2319d5bb-8cbf-439a-ca1a-85b888f442f4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 5000)\n",
        "tokenizer.fit_on_texts(sentences_train)\n",
        "\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
        "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
        "\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(sentences_train[2])\n",
        "print(X_train[2])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt_yU9nXZAFq",
        "outputId": "3023a52a-b098-478c-fd39-0a26c894593c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The acting is terrible, and the writing is worse.  \n",
            "[1, 35, 4, 136, 2, 1, 158, 4, 159]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R4fVLJsmZADs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BGqIZhHmZAAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aAESm41dY_9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "79uiVnhCY_60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lpHidcvMY_3z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}